/*
 * This Groovy source file was generated by the Gradle 'init' task.
 */
package imply

import com.opencsv.CSVParser
import com.opencsv.CSVWriter
import com.xlson.groovycsv.*
import groovy.util.logging.Log
import org.apache.avro.file.*
import org.apache.avro.generic.*

import groovy.json.*

//java -cp app.jar imply.DataSourceCompaction
//gradle run --args='../'

@Log
class DataSourceCompaction {

    final static String DEFAULT_BASE_DIR = "./conf"

    static void main(String[] args) {

        HashMap mergedDataSource = [:]
        if (args.size() == 0) {
            log.info "No directory argument given; Running Demo Mode."
            mergedDataSource = compactDataSources(DEFAULT_BASE_DIR)
        } else if (args.size() == 1) {
            log.info "Directory argument ${args[0]} passed in for processing."
            if (new File(args[0]).exists()) {
                mergedDataSource = compactDataSources(args[0])
            } else {
                log.severe "Argument ${new File(args[0]).absolutePath} not a valid directory."
                System.exit(0)
            }
        } else {
            log.severe "Too many arguments (${args.size()}) passed in, expected 1 or 0; Shutting down."
            System.exit(0)
        }

        if (mergedDataSource.size() > 0) {

            //What is the city with the largest population?
            /*def lisOfPopulations = mergedDataSource.collect { it.value.get("population") as Long }
            def largestPopulation = lisOfPopulations.max()
            def largestCity = mergedDataSource.find { key, value -> value.getAt("population") as Long == largestPopulation }
            log.info "The city with the largest population is: ${largestCity.value.getAt("name")}, ${largestCity.value.getAt("country")}
            with a population of ${largestCity.value.getAt("population")}"*/

            //What is the total population of all cities in Brazil (CountryCode == BRA)?
            /*def braTotalPopulation = 0;
            mergedDataSource.each {
                if (it.value.get("country").toString().equalsIgnoreCase("BRA")) {
                    //log.info "BRA: ${it.value.get("name").toString()} - ${it.value.get("population").toString()}"
                    braTotalPopulation += it.value.get("population")
                } else {
                    return
                }
            }
            log.info "The total population for Brazil amongst the dataset is: ${braTotalPopulation}"*/
        }

    }

    //*********************************************************************************************************************//

    /**
     * Finds datasources to process where datasources are: .json, .csv, .avro files.
     *
     * @param folder
     * @return
     */
    def static findDataSourceFiles(File folder) {

        File[] avro = folder.listFiles(
                { dir, file -> file ==~ /.*\.[a][v][r][o]/ } as FilenameFilter
        )?.toList()
        log.info "Found ${avro.size()} .avro files in ${folder.path}."

        File[] json = folder.listFiles(
                { dir, file -> file ==~ /.*\.[j][s][o][n]/ } as FilenameFilter
        )?.toList()
        log.info "Found ${json.size()} .json files in ${folder.path}."

        File[] csv = folder.listFiles(
                { dir, file -> file ==~ /.*\.[c][s][v]/ } as FilenameFilter
        )?.toList()
        log.info "Found ${csv.size()} .csv files in ${folder.path}."

        return avro + csv + json
    }

    /**
     * Helper method to output given datasource data to a comma delimited, non-quoted .csv file
     *
     * @param fileData
     * @return
     */
    def static writeDataToCSV(Map fileData) {

        File file = new File("../CityList.${System.currentTimeMillis()}.csv");
        FileWriter outputfile = new FileWriter(file);
        CSVWriter writer = new CSVWriter(outputfile, CSVWriter.DEFAULT_SEPARATOR, CSVWriter.NO_QUOTE_CHARACTER,
                CSVWriter.DEFAULT_ESCAPE_CHARACTER, CSVWriter.RFC4180_LINE_END);

        String[] header = [ "Name", "CountryCode", "Population" ]
        writer.writeNext(header);

        fileData.each { key, value ->
            def city = value.getAt("name").toString()
            def country = value.getAt("country").toString()
            def pop = value.getAt("population").toString()
            String[] row = [city, country, pop]
            writer.writeNext(row)
        }
        writer.close();
    }

    /**
     * Helper method that parses data from a datasource file. Extracts Name, CountryCode and Population
     * while removing duplicate entries.
     *
     * @param fileToProcess
     * @param processedRecords
     * @return
     */
    def static processDataFromSource(File fileToProcess, HashMap processedRecords) { //TODO Optimization for async

        def totalRowsProcessed = 0
        def filename = fileToProcess.getName()
        CharSequence fileTokenizers = new StringBuffer(".-_ ")
        def tokens = filename.tokenize(fileTokenizers)

        //Switch on file type and parse data accordingly.
        def fileExt = tokens[tokens.size() - 1].toLowerCase()
        switch (fileExt) {
            case "avro":
                DataInputStream inputStream = fileToProcess.newDataInputStream()
                DataFileStream<GenericRecord> parsedFileData = new DataFileStream<>(inputStream, new GenericDatumReader<GenericRecord>())
                parsedFileData.each { GenericRecord line ->
                    def city = line.get("Name").toString().trim()
                    def country = line.get("CountryCode").toString().trim()
                    def pop = line.get("Population") as Long
                    processedRecords.put("${city},${country}", ["name" : city, "country" : country, "population" : pop])
                    totalRowsProcessed++
                }
                break
            case "json":
                def parser = new JsonSlurper().setType(JsonParserType.LAX)
                def parsedFileData = parser.parse(fileToProcess, "UTF-8")
                parsedFileData.each { line ->
                    def city = line.Name.trim()
                    def country = line.CountryCode
                    def pop = line.Population as Long
                    processedRecords.put("${city},${country}", ["name" : city, "country" : country, "population" : pop])
                    totalRowsProcessed++
                }
            case "csv":
                def parsedFileData = new CsvParser().parse(fileToProcess.newReader(),
                        separator: CSVParser.DEFAULT_SEPARATOR, quoteChar: CSVParser.DEFAULT_QUOTE_CHARACTER, charset: "UTF-8")
                parsedFileData.each { line ->
                    def city = line.Name.trim()
                    def country = line.CountryCode
                    def pop = line.Population as Long
                    processedRecords.put("${city},${country}", ["name": city, "country": country, "population": pop])
                    totalRowsProcessed++
                }
                break
            default:
                log.error "Bad file? Shouldn't happen..."
                break
        }

        log.info "Processed ${totalRowsProcessed} lines of data from file: $fileToProcess.name"
        return totalRowsProcessed
    }

    /**
     * Main method to run compaction on datasource files where compaction means: remove duplicates and
     * generate a single .csv datasource, sorted by the city field.
     *
     * @param BASE_DIR
     * @return
     */
    def static compactDataSources(String BASE_DIR) {

        def compactedData = [] as HashMap // Optimization to remove duplicates
        def highestPopulation = -1 //TODO Optimization to find highest pop while traversing through data vs. after.

        File folderToProcess = new File(BASE_DIR)

        if (folderToProcess.isDirectory()) {

            File[] filesToCompact = findDataSourceFiles(folderToProcess)
            log.info "Compacting ${filesToCompact.length} datasource files."

            def totalRowsProccessed = 0;
            filesToCompact.each {totalRowsProccessed += processDataFromSource(it, compactedData) } //TODO Optimization for async

            def sortedAndCompactedData = compactedData.sort {  a,  b ->
                def cityA = a.value.getAt("name").toString().toLowerCase().replaceAll('\\[', "").replaceAll('\\(', "")
                def cityB = b.value.getAt("name").toString().toLowerCase().replaceAll('\\[', "").replaceAll('\\(', "")
                cityA <=> cityB
            }

            writeDataToCSV(sortedAndCompactedData)

            log.info "Processed ${sortedAndCompactedData.size()} unique records from ${totalRowsProccessed} total records."
            return compactedData
        } else {
            log.info "Found a Directory $folderToProcess, processing folder."
            compactDataSources(folderToProcess)
        }

    }

}